import telebot
import requests
import jsons
from environs import Env

from Class_ModelResponse import ModelResponse


# --- config ---
env = Env()
env.read_env()

TG_TOKEN = env("API_TOKEN")
bot = telebot.TeleBot(TG_TOKEN)

LM_BASE = "http://localhost:1234"
LM_CHAT = f"{LM_BASE}/v1/chat/completions"
LM_MODELS = f"{LM_BASE}/v1/models"

# –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
ctx_store: dict[int, str] = {}


# --- helpers ---
def get_ctx(user_id: int) -> str:
    return ctx_store.get(user_id, "")


def set_ctx(user_id: int, value: str) -> None:
    ctx_store[user_id] = value


def drop_ctx(user_id: int) -> None:
    ctx_store.pop(user_id, None)


def lm_current_model() -> str | None:
    r = requests.get(LM_MODELS, timeout=10)
    if r.status_code != 200:
        return None
    data = r.json()
    if not data.get("data"):
        return None
    return data["data"][0].get("id")


def build_prompt(history: str) -> str:
    return (
        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–µ–±–µ –ø–µ—Ä–µ–¥–∞—é—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
        "user: <—Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è>\n"
        "assistant: <–æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞>\n"
        "–ü—Ä–æ–¥–æ–ª–∂–∏ –¥–∏–∞–ª–æ–≥ –∏ –æ—Ç–≤–µ—Ç—å –∑–∞ assistant.\n\n"
        "–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n"
        f"{history}\n"
        "assistant:"
    )


def lm_answer(prompt: str) -> str:
    payload = {"messages": [{"role": "user", "content": prompt}]}
    r = requests.post(LM_CHAT, json=payload, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"LM Studio –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {r.status_code}")
    parsed: ModelResponse = jsons.loads(r.text, ModelResponse)
    return parsed.choices[0].message.content.strip()


# --- commands ---
@bot.message_handler(commands=["start"])
def cmd_start(msg):
    text = (
        "–ü—Ä–∏–≤–µ—Ç! –Ø Telegram-–±–æ—Ç, –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–π –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ LM Studio.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/start  - –ø–æ–º–æ—â—å\n"
        "/model  - –ø–æ–∫–∞–∑–∞—Ç—å –º–æ–¥–µ–ª—å\n"
        "/clear  - –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç\n\n"
        "–ù–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –æ—Ç–≤–µ—á—É —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞."
    )
    bot.reply_to(msg, text)


@bot.message_handler(commands=["model"])
def cmd_model(msg):
    try:
        name = lm_current_model()
    except Exception as e:
        bot.reply_to(msg, f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LM Studio: {e}")
        return

    if name:
        bot.reply_to(msg, f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å: {name}")
    else:
        bot.reply_to(msg, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏.")


@bot.message_handler(commands=["clear"])
def cmd_clear(msg):
    uid = msg.from_user.id
    drop_ctx(uid)
    bot.reply_to(msg, "üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ!")


# --- main chat ---
@bot.message_handler(func=lambda m: True)
def on_text(msg):
    uid = msg.from_user.id
    q = msg.text

    history = get_ctx(uid)
    history = f"{history}user: {q}\n"

    prompt = build_prompt(history)

    try:
        reply = lm_answer(prompt)
    except Exception as e:
        bot.reply_to(msg, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏: {e}")
        return

    history = f"{history}assistant: {reply}\n"
    set_ctx(uid, history)

    bot.reply_to(msg, reply)


if __name__ == "__main__":
    bot.polling(none_stop=True)






